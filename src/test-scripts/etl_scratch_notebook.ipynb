{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.abspath('../'))\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.path.abspath(''), os.pardir, os.pardir)\n",
    "base_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_filepath = 'file://' + os.path.abspath(os.path.join(base_path, 'data', 'delta'))\n",
    "print(save_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filepath = 'file://' + os.path.abspath(os.path.join(base_path, 'data', 'tmp'))\n",
    "temp_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://datasets.imdbws.com'\n",
    "\n",
    "files_list = [\n",
    "        \"name.basics.tsv.gz\",\n",
    "        \"title.akas.tsv.gz\",\n",
    "        \"title.basics.tsv.gz\",\n",
    "        \"title.crew.tsv.gz\",\n",
    "        \"title.episode.tsv.gz\",\n",
    "        \"title.principals.tsv.gz\",\n",
    "        \"title.ratings.tsv.gz\"]\n",
    "        \n",
    "temp_filepath = os.path.abspath(os.path.join(os.path.abspath(''), \"../..\", 'data', 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "for file in files_list:\n",
    "    data[file] = pd.read_csv(temp_filepath+'/'+file, sep = '\\t', nrows=100, compression='gzip',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.akas.tsv.gz\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.basics.tsv.gz\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.crew.tsv.gz\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.episode.tsv.gz\"].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.principals.tsv.gz\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.ratings.tsv.gz\"].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/Users/akshayiyer/Library/Java/JavaVirtualMachines/jdk8u222-b10/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "%set_env JAVA_HOME=/Users/akshayiyer/Library/Java/JavaVirtualMachines/jdk8u222-b10/Contents/Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import datetime\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *\n",
    "import sys\n",
    "\n",
    "sys.path.insert(1, os.path.abspath('../'))\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session(master,endpoint=None):\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0,io.delta:delta-core_2.11:0.3.0\") \\\n",
    "            .config(\"fs.s3a.endpoint\",endpoint)\\\n",
    "            .config(\"spark.sql.autoBroadcastJoinThreshold\",-1) \\\n",
    "            .appName(\"udacity-dend-capstone-etl-proj\")\\\n",
    "            .master(master)\\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://172.20.10.2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://127.0.0.1:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>udacity-dend-capstone-etl-proj</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x10a9e9cf8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark://127.0.0.1:7077\n",
    "spark = create_spark_session(\"spark://127.0.0.1:7077\",\"s3.us-west-2.amazonaws.com\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download files to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://datasets.imdbws.com'\n",
    "\n",
    "files_list = [\n",
    "        \"name.basics.tsv.gz\",\n",
    "        \"title.akas.tsv.gz\",\n",
    "        \"title.basics.tsv.gz\",\n",
    "        \"title.crew.tsv.gz\",\n",
    "        \"title.episode.tsv.gz\",\n",
    "        \"title.principals.tsv.gz\",\n",
    "        \"title.ratings.tsv.gz\"]\n",
    "        \n",
    "download_directory = os.path.abspath(os.path.join(os.path.abspath(''), '../..', 'data', 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.download_files_to_local(base_url, files_list, download_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process name.basics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "names_schema = StructType([\n",
    "                    StructField('nconst', StringType(), True),\n",
    "                    StructField('primaryName', StringType(), True),\n",
    "                    StructField('birthYear', IntegerType(), True),\n",
    "                    StructField('deathYear', IntegerType(), True),\n",
    "                    StructField('primaryProfession', StringType(), True),\n",
    "                    StructField('knownForTitles', StringType(), True),\n",
    "                    StructField('broken', StringType(), True)\n",
    "                        ])\n",
    "'''\n",
    "\n",
    "temp_filepath = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/tmp'\n",
    "file = 'name.basics.tsv.gz'\n",
    "\n",
    "names_df_raw = spark.read.load(\n",
    "    temp_filepath+'/'+file,\n",
    "    format=\"csv\", \n",
    "    sep=\"\\t\", \n",
    "    inferSchema=\"true\", \n",
    "    header=\"true\",\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    nullValue = '\\\\N',\n",
    "    quote = '' # this will ignore using quotes as a qualifier. This helps reduce malformed records. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9863863"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: integer (nullable = true)\n",
      " |-- deathYear: integer (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      "\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "| artistId|    primaryName|birthYear|deathYear|   primaryProfession|      knownForTitles|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0053137,tt00504...|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|  actress,soundtrack|tt0037382,tt00383...|\n",
      "|nm0000003|Brigitte Bardot|     1934|     null|actress,soundtrac...|tt0049189,tt00573...|\n",
      "|nm0000004|   John Belushi|     1949|     1982|actor,soundtrack,...|tt0072562,tt00779...|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|writer,director,a...|tt0083922,tt00694...|\n",
      "+---------+---------------+---------+---------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df_raw.printSchema()\n",
    "names_df = names_df_raw.withColumnRenamed(\"nconst\",\"artistId\")\n",
    "names_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For very small number of cases, the birthYear and deathYear is less than 1000 (15 and 18 respectively)\n",
    "# Spot checking a few entries, this mostly seems to be an error in the dataset\n",
    "# Rather than removing these entries, marking these fields as null seems appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df.filter(names_df.birthYear < 1000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names_df.filter(names_df.deathYear < 1000).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "|artistId |primaryName    |primaryProfession             |knownForTitles                         |birthYear|deathYear|\n",
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "|nm0000001|Fred Astaire   |soundtrack,actor,miscellaneous|tt0053137,tt0050419,tt0043044,tt0072308|1899     |1987     |\n",
      "|nm0000002|Lauren Bacall  |actress,soundtrack            |tt0037382,tt0038355,tt0071877,tt0117057|1924     |2014     |\n",
      "|nm0000003|Brigitte Bardot|actress,soundtrack,producer   |tt0049189,tt0057345,tt0059956,tt0054452|1934     |null     |\n",
      "|nm0000004|John Belushi   |actor,soundtrack,writer       |tt0072562,tt0077975,tt0078723,tt0080455|1949     |1982     |\n",
      "|nm0000005|Ingmar Bergman |writer,director,actor         |tt0083922,tt0069467,tt0050986,tt0050976|1918     |2007     |\n",
      "|nm0000006|Ingrid Bergman |actress,soundtrack,producer   |tt0038787,tt0071877,tt0036855,tt0038109|1915     |1982     |\n",
      "|nm0000007|Humphrey Bogart|actor,soundtrack,producer     |tt0043265,tt0034583,tt0033870,tt0037382|1899     |1957     |\n",
      "|nm0000008|Marlon Brando  |actor,soundtrack,director     |tt0070849,tt0078788,tt0044081,tt0068646|1924     |2004     |\n",
      "|nm0000009|Richard Burton |actor,producer,soundtrack     |tt0057877,tt0059749,tt0061184,tt0087803|1925     |1984     |\n",
      "|nm0000010|James Cagney   |actor,soundtrack,director     |tt0042041,tt0035575,tt0031867,tt0029870|1899     |1986     |\n",
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def fix_year(col):\n",
    "    # Get today's date\n",
    "    now = datetime.datetime.now()\n",
    "    \n",
    "    fix_year_func = (\n",
    "                F.when(F.col(col)<1000,None)\n",
    "                 .when(F.col(col)>now.year,None)\n",
    "                 .otherwise(F.col(col))\n",
    "                )\n",
    "    return fix_year_func\n",
    "\n",
    "\n",
    "names_df = names_df.withColumn(\"birthYear_fixed\",fix_year('birthYear'))\\\n",
    "            .drop(\"birthYear\")\\\n",
    "            .withColumnRenamed(\"birthYear_fixed\", \"birthYear\")\n",
    "\n",
    "names_df = names_df.withColumn(\"deathYear_fixed\",fix_year('deathYear'))\\\n",
    "             .drop(\"deathYear\")\\\n",
    "             .withColumnRenamed(\"deathYear_fixed\", \"deathYear\")\n",
    "\n",
    "names_df.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_df = names_df.select(\"artistId\",\"primaryName\",\"birthYear\",\"deathYear\")\n",
    "artists_prmry_prfsn_df = names_df.select(\"artistId\",\\\n",
    "                                         F.explode(F.split(F.col(\"primaryProfession\"),\",\")).alias(\"primaryProfession\"))\n",
    "artists_knwn_fr_ttls_df = names_df.select(\"artistId\",\n",
    "                                          F.explode(F.split(F.col(\"knownForTitles\"),\",\")).alias(\"knownForTitles\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+---------+---------+\n",
      "| artistId|    primaryName|birthYear|deathYear|\n",
      "+---------+---------------+---------+---------+\n",
      "|nm0000001|   Fred Astaire|     1899|     1987|\n",
      "|nm0000002|  Lauren Bacall|     1924|     2014|\n",
      "|nm0000003|Brigitte Bardot|     1934|     null|\n",
      "|nm0000004|   John Belushi|     1949|     1982|\n",
      "|nm0000005| Ingmar Bergman|     1918|     2007|\n",
      "+---------+---------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-----------------+\n",
      "| artistId|primaryProfession|\n",
      "+---------+-----------------+\n",
      "|nm0000001|       soundtrack|\n",
      "|nm0000001|            actor|\n",
      "|nm0000001|    miscellaneous|\n",
      "|nm0000002|          actress|\n",
      "|nm0000002|       soundtrack|\n",
      "+---------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+--------------+\n",
      "| artistId|knownForTitles|\n",
      "+---------+--------------+\n",
      "|nm0000001|     tt0053137|\n",
      "|nm0000001|     tt0050419|\n",
      "|nm0000001|     tt0043044|\n",
      "|nm0000001|     tt0072308|\n",
      "|nm0000002|     tt0037382|\n",
      "+---------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.show(5)\n",
    "artists_prmry_prfsn_df.show(5)\n",
    "artists_knwn_fr_ttls_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---------+--------------------+------------------+------------------+\n",
      "|summary| artistId|         primaryName|         birthYear|         deathYear|\n",
      "+-------+---------+--------------------+------------------+------------------+\n",
      "|  count|  9863863|             9863863|            495715|            173945|\n",
      "|   mean|     null|            Infinity|1950.7750844739417|1988.7498807094196|\n",
      "| stddev|     null|                 NaN| 33.20074219447096| 29.87583815392508|\n",
      "|    min|nm0000001|!'aru Ikhuisi Pie...|              1048|              1022|\n",
      "|    max|nm9993719|þórunn Ósk Morinó...|              2019|              2020|\n",
      "+-------+---------+--------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.describe().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframes to Parquet/Delta tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/parquet'\n",
    "save_file_path_delta = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/delta'\n",
    "\n",
    "#Write to parquet files\n",
    "artists_df.write.mode('overwrite').parquet(save_file_path+\"artists.parquet\")\n",
    "artists_prmry_prfsn_df.write.mode('overwrite').parquet(save_file_path+\"artists_prmry_profession.parquet\")\n",
    "artists_knwn_fr_ttls_df.write.mode('overwrite').parquet(save_file_path+\"artists_knwnfor_titles.parquet\")\n",
    "\n",
    "# Write artist dataframes to delta tables\n",
    "artists_df.write.format('delta').partitionBy(\"birthYear\").mode('overwrite').save(\n",
    "    os.path.join(save_file_path_delta, \"artists\"))\n",
    "\n",
    "artists_prmry_prfsn_df.write.format(\"delta\").mode('overwrite').save(\n",
    "    os.path.join(save_file_path_delta, \"artists_prmry_profession\"))\n",
    "\n",
    "artists_knwn_fr_ttls_df.write.format(\"delta\").mode('overwrite').save(\n",
    "    os.path.join(save_file_path_delta, \"artists_knwnfor_titles\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process title.basics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filepath = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/tmp'\n",
    "file = 'title.basics.tsv.gz'\n",
    "\n",
    "title_basics_df_raw = spark.read.load(\n",
    "    temp_filepath+'/'+file,\n",
    "    format=\"csv\", \n",
    "    sep=\"\\t\", \n",
    "    inferSchema=\"true\", \n",
    "    header=\"true\",\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    nullValue = '\\\\N',\n",
    "    quote = '' # this will ignore using quotes as a qualifier. This helps reduce malformed records. \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_df_raw.printSchema()\n",
    "title_basics_df = title_basics_df_raw.withColumnRenamed(\"tconst\",\"titleId\")\n",
    "title_basics_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_basics_df.describe(\"startYear\",\"endYear\",\"runtimeMinutes\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = title_basics_df.select(\"titleId\",\"titleType\",\"primaryTitle\",\"originalTitle\",\\\n",
    "                                   \"isAdult\",\"startYear\",\"endYear\",\"runtimeMinutes\")\n",
    "\n",
    "titles_genres_df = title_basics_df.select(\"titleId\",F.explode(F.split(F.col(\"genres\"),\",\")).alias(\"genres\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.show(5)\n",
    "titles_genres_df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframes to Parquet/Delta tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/parquet'\n",
    "save_file_path_delta = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/delta/'\n",
    "\n",
    "# Write to Parquet\n",
    "titles_df.write.mode('overwrite').partitionBy(\"startYear\").parquet(save_file_path+\"titles.parquet\")\n",
    "titles_genres_df.write.mode('overwrite').parquet(save_file_path+\"titles_genres.parquet\")\n",
    "\n",
    "# Write to Delta\n",
    "titles_df.write.format(\"delta\").mode('overwrite').partitionBy(\n",
    "    \"startYear\").save(os.path.join(save_file_path_delta, \"titles\"))\n",
    "\n",
    "titles_genres_df.write.format(\"delta\").mode('overwrite').save(\n",
    "    os.path.join(save_file_path_delta, \"titles_genres\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process title.ratings file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_filepath = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/tmp'\n",
    "file = 'title.ratings.tsv.gz'\n",
    "\n",
    "title_ratings_df_raw = spark.read.load(\n",
    "    temp_filepath+'/'+file,\n",
    "    format=\"csv\", \n",
    "    sep=\"\\t\", \n",
    "    inferSchema=\"true\", \n",
    "    header=\"true\",\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True,\n",
    "    nullValue = '\\\\N',\n",
    "    quote = '' # this will ignore using quotes as a qualifier. This helps reduce malformed records. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df_raw.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df_raw.printSchema()\n",
    "title_ratings_df = title_ratings_df_raw.withColumnRenamed(\"tconst\",\"titleId\")\n",
    "title_ratings_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/'\n",
    "\n",
    "title_ratings_df.write.mode('overwrite').parquet(save_file_path+\"title_ratings.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Joining titles, title_ratings and title_genres datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_filepath = \"file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/title_ratings.parquet\"\n",
    "titles_filepath = \"file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/titles.parquet\"\n",
    "title_genres_filepath = \"file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/titles_genres.parquet\"\n",
    "\n",
    "title_ratings_df = spark.read.parquet(title_ratings_filepath)\n",
    "titles_df = spark.read.parquet(titles_filepath)\n",
    "title_genres_df = spark.read.parquet(title_genres_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df = titles_df.join(title_ratings_df, \"titleId\").join(title_genres_df,\"titleId\")\n",
    "title_genres_ratings_df = title_genres_ratings_df\\\n",
    "                            .groupBy(\"startYear\",\"genres\")\\\n",
    "                            .agg({\"averageRating\":\"mean\",\"numVotes\":\"sum\",\"titleId\":\"count\"})\\\n",
    "                            .withColumnRenamed(\"avg(averageRating)\",\"averageRating\")\\\n",
    "                            .withColumnRenamed(\"sum(numVotes)\",\"numVotes\")\\\n",
    "                            .withColumnRenamed(\"count(titleId)\",\"numTitles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.join(title_ratings_df, \"titleId\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df.join(title_genres_df,\"titleId\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_sql_df = title_ratings_df.createOrReplaceTempView(\"title_ratings_df\")\n",
    "titles_sql_df = titles_df.createOrReplaceTempView(\"titles\")\n",
    "title_genres_sql_df = title_genres_df.createOrReplaceTempView(\"title_genres\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "select count(distinct titleId)\n",
    "from title_genres\n",
    "''').show()\n",
    "\n",
    "spark.sql('''\n",
    "select count(distinct titleId)\n",
    "from titles\n",
    "''').show()\n",
    "\n",
    "spark.sql('''\n",
    "select count(distinct titleId)\n",
    "from title_ratings_df\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "select tr.*\n",
    "from title_ratings_df tr\n",
    "left join titles t on tr.titleId = t.titleId\n",
    "where t.titleId is null\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df = spark.sql('''\n",
    "select tr.titleId, tr.averageRating, tr.numVotes, tg.genres, t.startYear\n",
    "from title_ratings_df tr\n",
    "inner join title_genres tg on tr.titleId = tg.titleId\n",
    "inner join titles t on tg.titleId = t.titleId\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df = title_genres_ratings_df\\\n",
    "                            .groupBy(\"startYear\",\"genres\")\\\n",
    "                            .agg({\"averageRating\":\"mean\",\"numVotes\":\"sum\",\"titleId\":\"count\"})\\\n",
    "                            .withColumnRenamed(\"avg(averageRating)\",\"averageRating\")\\\n",
    "                            .withColumnRenamed(\"sum(numVotes)\",\"numVotes\")\\\n",
    "                            .withColumnRenamed(\"count(titleId)\",\"numTitles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_genres_ratings_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/'\n",
    "\n",
    "title_genres_ratings\\\n",
    "    .write.mode('overwrite')\\\n",
    "    .partitionBy(\"startYear\")\\\n",
    "    .parquet(save_file_path+\"title_genres_ratings.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join title and title_ratings to get top 3 movies by year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = os.path.join(os.path.abspath(''), os.pardir, os.pardir)\n",
    "\n",
    "save_filepath = os.path.abspath(os.path.join(base_path, 'data', 'delta'))\n",
    "\n",
    "temp_filepath = os.path.abspath(os.path.join(base_path, 'data', 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df = spark.read.format(\"delta\").load(os.path.join(save_filepath,'titles'))\n",
    "title_ratings_df = spark.read.format(\"delta\").load(os.path.join(save_filepath,'title_ratings'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.createOrReplaceTempView(\"titles\")\n",
    "title_ratings_df.createOrReplaceTempView(\"title_ratings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql('''\n",
    "select distinct titleType\n",
    "from titles\n",
    "''').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_5_movies_by_year_df = spark.sql('''\n",
    "select \n",
    "    titleId, \n",
    "    titleType,\n",
    "    startYear,\n",
    "    primaryTitle,\n",
    "    averageRating,\n",
    "    numVotes,\n",
    "    rank\n",
    "from (\n",
    "    select \n",
    "        t.titleId, \n",
    "        t.titleType,\n",
    "        t.startYear,\n",
    "        t.primaryTitle,\n",
    "        tr.averageRating,\n",
    "        tr.numVotes,\n",
    "        rank() over (partition by t.titleType, t.startYear order by averageRating desc) as rank\n",
    "    from titles t\n",
    "    inner join title_ratings tr \n",
    "        on t.titleId = tr.titleId\n",
    "    where t.titleType in ('movie', 'tvMovie')) tmp\n",
    "where rank < 6\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_df.select(F.countDistinct(\"titleId\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_source = title_df.select(\"titleId\").distinct().count()\n",
    "print(count_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dest = title_ratings_df.select(\"titleId\").distinct().count()\n",
    "print(count_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ratings_df.join(title_df, \"titleId\").select(\"titleId\").distinct().count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.7_udacityCapstone",
   "language": "python",
   "name": "python3.7_udacitycapstone"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
