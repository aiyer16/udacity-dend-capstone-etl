{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.abspath('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://datasets.imdbws.com'\n",
    "\n",
    "files_list = [\n",
    "        \"name.basics.tsv.gz\",\n",
    "        \"title.akas.tsv.gz\",\n",
    "        \"title.basics.tsv.gz\",\n",
    "        \"title.crew.tsv.gz\",\n",
    "        \"title.episode.tsv.gz\",\n",
    "        \"title.principals.tsv.gz\",\n",
    "        \"title.ratings.tsv.gz\"]\n",
    "        \n",
    "temp_filepath = os.path.abspath(os.path.join(os.path.abspath(''), os.pardir, 'data', 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.download_files_to_local(base_url, files_list, temp_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = dict()\n",
    "\n",
    "for file in files_list:\n",
    "    data[file] = pd.read_csv(temp_filepath+'/'+file, sep = '\\t', nrows=100, compression='gzip',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['name.basics.tsv.gz']['deathYear'] = data['name.basics.tsv.gz']['deathYear'].replace('\\\\N','') \n",
    "data['name.basics.tsv.gz'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title.akas.tsv.gz']['region'] = data['title.akas.tsv.gz']['region'].replace('\\\\N','XX') \n",
    "data['title.akas.tsv.gz'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.basics.tsv.gz\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.crew.tsv.gz\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.episode.tsv.gz\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.principals.tsv.gz\"].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.ratings.tsv.gz\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"title.episode.tsv.gz\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploration using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAVA_HOME=/Users/akshayiyer/Library/Java/JavaVirtualMachines/jdk8u222-b10/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "%set_env JAVA_HOME=/Users/akshayiyer/Library/Java/JavaVirtualMachines/jdk8u222-b10/Contents/Home"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import configparser\n",
    "import datetime\n",
    "import os\n",
    "import util\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_spark_session(master,endpoint=None):\n",
    "    spark = SparkSession \\\n",
    "            .builder \\\n",
    "            .config(\"spark.jars.packages\", \"org.apache.hadoop:hadoop-aws:2.7.0\") \\\n",
    "            .config(\"fs.s3a.endpoint\",endpoint)\\\n",
    "            .appName(\"udacity-dend-data-lake-proj\")\\\n",
    "            .master(master)\\\n",
    "            .getOrCreate()\n",
    "    \n",
    "    return spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.0.11:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v2.4.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>spark://127.0.0.1:7077</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>udacity-dend-data-lake-proj</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x112d7a978>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#spark://127.0.0.1:7077\n",
    "spark = create_spark_session(\"spark://127.0.0.1:7077\",\"s3.us-west-2.amazonaws.com\")\n",
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download files to local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'https://datasets.imdbws.com'\n",
    "\n",
    "files_list = [\n",
    "        \"name.basics.tsv.gz\",\n",
    "        \"title.akas.tsv.gz\",\n",
    "        \"title.basics.tsv.gz\",\n",
    "        \"title.crew.tsv.gz\",\n",
    "        \"title.episode.tsv.gz\",\n",
    "        \"title.principals.tsv.gz\",\n",
    "        \"title.ratings.tsv.gz\"]\n",
    "        \n",
    "download_directory = os.path.abspath(os.path.join(os.path.abspath(''), os.pardir, 'data', 'tmp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "util.download_files_to_local(base_url, files_list, download_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process name_basics file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "names_schema = StructType([\n",
    "                    StructField('nconst', StringType(), True),\n",
    "                    StructField('primaryName', StringType(), True),\n",
    "                    StructField('birthYear', IntegerType(), True),\n",
    "                    StructField('deathYear', IntegerType(), True),\n",
    "                    StructField('primaryProfession', StringType(), True),\n",
    "                    StructField('knownForTitles', StringType(), True),\n",
    "                    StructField('broken', StringType(), True)\n",
    "                        ])\n",
    "'''\n",
    "\n",
    "temp_filepath = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/tmp'\n",
    "file = 'name.basics.tsv.gz'\n",
    "\n",
    "names_df = spark.read.load(\n",
    "    temp_filepath+'/'+file,\n",
    "    format=\"csv\", \n",
    "    sep=\"\\t\", \n",
    "    inferSchema=\"true\", \n",
    "    header=\"true\",\n",
    "    ignoreLeadingWhiteSpace=True,\n",
    "    ignoreTrailingWhiteSpace=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- nconst: string (nullable = true)\n",
      " |-- primaryName: string (nullable = true)\n",
      " |-- birthYear: string (nullable = true)\n",
      " |-- deathYear: string (nullable = true)\n",
      " |-- primaryProfession: string (nullable = true)\n",
      " |-- knownForTitles: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "names_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "|nconst   |primaryName    |primaryProfession             |knownForTitles                         |birthYear|deathYear|\n",
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "|nm0000001|Fred Astaire   |soundtrack,actor,miscellaneous|tt0043044,tt0072308,tt0053137,tt0050419|1899     |1987     |\n",
      "|nm0000002|Lauren Bacall  |actress,soundtrack            |tt0071877,tt0117057,tt0038355,tt0037382|1924     |2014     |\n",
      "|nm0000003|Brigitte Bardot|actress,soundtrack,producer   |tt0057345,tt0049189,tt0059956,tt0054452|1934     |null     |\n",
      "|nm0000004|John Belushi   |actor,writer,soundtrack       |tt0078723,tt0080455,tt0077975,tt0072562|1949     |1982     |\n",
      "|nm0000005|Ingmar Bergman |writer,director,actor         |tt0050976,tt0083922,tt0069467,tt0050986|1918     |2007     |\n",
      "|nm0000006|Ingrid Bergman |actress,soundtrack,producer   |tt0071877,tt0036855,tt0038109,tt0038787|1915     |1982     |\n",
      "|nm0000007|Humphrey Bogart|actor,soundtrack,producer     |tt0033870,tt0034583,tt0037382,tt0043265|1899     |1957     |\n",
      "|nm0000008|Marlon Brando  |actor,soundtrack,director     |tt0068646,tt0047296,tt0078788,tt0070849|1924     |2004     |\n",
      "|nm0000009|Richard Burton |actor,producer,soundtrack     |tt0087803,tt0057877,tt0059749,tt0061184|1925     |1984     |\n",
      "|nm0000010|James Cagney   |actor,soundtrack,director     |tt0055256,tt0029870,tt0031867,tt0035575|1899     |1986     |\n",
      "+---------+---------------+------------------------------+---------------------------------------+---------+---------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get today's date\n",
    "now = datetime.datetime.now()\n",
    "\n",
    "fix_birthYear_func = (\n",
    "                F.when(F.col('birthYear')<1000,None)\n",
    "                 .when(F.col('birthYear')>now.year,None)\n",
    "                 .when(F.col('birthYear')=='\\\\N',None)\n",
    "                 .otherwise(F.col('birthYear'))\n",
    "                )\n",
    "\n",
    "names_df2 = names_df.withColumn(\"birthYear_fixed\",fix_birthYear_func)\\\n",
    "        .drop(\"birthYear\")\\\n",
    "        .withColumnRenamed(\"birthYear_fixed\", \"birthYear\")\n",
    "\n",
    "fix_deathYear_func = (\n",
    "                F.when(F.col('deathYear')<1000,None)\n",
    "                 .when(F.col('deathYear')>now.year,None)\n",
    "                 .when(F.col('deathYear')=='\\\\N',None)\n",
    "                 .otherwise(F.col('deathYear'))\n",
    "                )\n",
    "\n",
    "names_df3 = names_df2.withColumn(\"deathYear_fixed\",fix_deathYear_func)\\\n",
    "         .drop(\"deathYear\")\\\n",
    "         .withColumnRenamed(\"deathYear_fixed\", \"deathYear\")\n",
    "\n",
    "names_df3.show(10, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_df = names_df3.select(\"nconst\",\"primaryName\",\"birthYear\",\"deathYear\").drop_duplicates()\n",
    "artists_prmry_prfsn_df = names_df3.select(\"nconst\",F.explode(F.split(F.col(\"primaryProfession\"),\",\")))\n",
    "artists_knwn_fr_ttls_df = names_df3.select(\"nconst\",F.explode(F.split(F.col(\"knownForTitles\"),\",\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------+---------+---------+\n",
      "|   nconst|   primaryName|birthYear|deathYear|\n",
      "+---------+--------------+---------+---------+\n",
      "|nm0000080|  Orson Welles|     1915|     1985|\n",
      "|nm0000092|   John Cleese|     1939|     null|\n",
      "|nm0000238| Shannon Tweed|     1957|     null|\n",
      "|nm0000282|Scott Bairstow|     1970|     null|\n",
      "|nm0000373|  Michael Dorn|     1952|     null|\n",
      "+---------+--------------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+-------------+\n",
      "|   nconst|          col|\n",
      "+---------+-------------+\n",
      "|nm0000001|   soundtrack|\n",
      "|nm0000001|        actor|\n",
      "|nm0000001|miscellaneous|\n",
      "|nm0000002|      actress|\n",
      "|nm0000002|   soundtrack|\n",
      "+---------+-------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+---------+---------+\n",
      "|   nconst|      col|\n",
      "+---------+---------+\n",
      "|nm0000001|tt0043044|\n",
      "|nm0000001|tt0072308|\n",
      "|nm0000001|tt0053137|\n",
      "|nm0000001|tt0050419|\n",
      "|nm0000002|tt0071877|\n",
      "+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "artists_df.show(5)\n",
    "artists_prmry_prfsn_df.show(5)\n",
    "artists_knwn_fr_ttls_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file_path = 'file:///Users/akshayiyer/Dev/GitHub/udacity-dend-capstone-etl/data/'\n",
    "\n",
    "artists_df.write.mode('overwrite').parquet(save_file_path+\"artists.parquet\")\n",
    "artists_prmry_prfsn_df.write.mode('overwrite').parquet(save_file_path+\"artists_prmry_profession.parquet\")\n",
    "artists_knwn_fr_ttls_df.write.mode('overwrite').parquet(save_file_path+\"artists_knwnfor_titles.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3 (udacity-capstone-etl)",
   "language": "python",
   "name": "udacity-dend-capstone-etl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
